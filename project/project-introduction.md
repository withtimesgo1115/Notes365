##  高性能分布式编译服务
### 项目背景
我们公司多数研发使用C++进行算法的开发，他们作为平台的用户每个MR在CI上会运行大量的编译作业，平台的可用性和性能显著影响研发的开发进度和开发体验。为了满足高可用高性能的诉求，我构建了这套分布式的编译服务。

在此之前，我们公司使用的是bazel提供的remote cache机制，在机房部署单个节点从而提供一个单机的remote cache地址。但是这种架构在可用性和性能上都无法满足越来越庞大的编译压力。于是，我们搭建了这套分布式编译服务。使得既可以使用到remote cache也可以使用到分布式节点来做编译，从而提高编译的并发，加速编译。

### 项目技术架构
Bazel + Spring Boot + Redis

当前技术选型可以满足项目场景的需求，引入过多的模块会增加项目复杂度

### 具体实现
实现一个server服务，一个worker服务。server中维护一个operation队列，和redis通信记录CAS的数据，同时和bazel client通信接收action，并把action派发给worker。worker则是维护了一个workers队列, 做具体的执行。

关键就在于实现了Remote Execution API。  
客户端需要提供：
- Command
- Action
- ContentAddressableStorage   

这些也被叫做action_digest，发给server，server安排对action_digest的执行。


### 改进点
#### cache目前存在节点本地
从成本方面考虑，我们的节点由固定节点和弹性节点组成。当前cache是保存在固定节点的/tmp/worker目录下的，这种方式实现起来相对简单，但是不如将cache存储在S3存储上好，这样的话cache不会因为节点存储达到阈值被剔除，影响编译的可用性，同时S3存储也更可靠。不过这种方式也存在问题，如果cache一直都不被清除，对象存储cache目录会越来越大，保存了很多失效的编译产物，需要有对应的清理机制。

#### 如何限流
对不同的编译Job进行优先级划分：  
1. 发包作业 > 编译作业 > 测试作业 > 代码风格检查等
2. 可以考虑在MR上通过用户指定标签来声明优先级。  

对于优先级高的Job，平台优先将资源分配给它，保证高优任务能够快速执行。在业务压力大的时候，低优先度的job会被放到阻塞队列中等待执行，从而使得平台的编译流量保持平稳。快速完成当前任务后可以从阻塞队列中获取任务来执行。

#### 定期reindex
由于我们使用了一部分弹性节点，所以reindex非常重要，不然redis中的记录可能不准确了。获取活跃workers，然后对于redis中的CAS记录取交集，进行一个更新，保证redis中的记录准确。

#### cache清除逻辑
当前用的是引用计数，cache命中率





### PVC Runner实现本地cache
